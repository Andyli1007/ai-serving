{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferencing MNIST ONNX Model using AI-Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST handwritten digit classification problem is a classic dataset used in computer vision and deep learning, and Convolutional Neural Network (CNN) is the current state-of-art architecture for image classification task.\n",
    "\n",
    "In this tutorial, we will use the Open Neural Network eXchange (ONNX) format to show how to deploy a pre-trained MNIST CNN model using AI-Serving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies\n",
    "We will install python libraries for data manipulation, image manipulation and display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites to run the notebook\n",
    "\n",
    "1. Download the pre-trained MNIST ONNX model file (mnist.tar.gz) from [here](https://onnxzoo.blob.core.windows.net/models/opset_8/mnist/mnist.tar.gz). For example, you could use `wget` and `tar` to download and uncompress the tar file.  Please, refer to [MNIST - Handwritten Digit Recognition](https://github.com/onnx/models/tree/master/vision/classification/mnist) for details about the MNIST CNN model. \n",
    "\n",
    "```bash\n",
    "wget https://onnxzoo.blob.core.windows.net/models/opset_8/mnist/mnist.tar.gz\n",
    "tar xvzf mnist.tar.gz\n",
    "```\n",
    "   \n",
    "2. Pull the latest docker image of AI-Serving with ONNX that leverages the CPU version of [ONNX Runtime](https://github.com/microsoft/onnxruntime). Please, refer to [Docker Containers for AI-Serving](https://github.com/autodeployai/ai-serving/tree/master/dockerfiles) about more docker images.\n",
    "\n",
    "```bash\n",
    "docker pull autodeployai/ai-serving\n",
    "```\n",
    "   \n",
    "3. Start a docker container of AI-Serving. The port `9090` is the port of HTTP endpoint while `9091` is for gRPC, you could see an error likes `Bind for 0.0.0.0:9090 failed: port is already allocated`, please use another new port instead of the first part as follows `-p $(NEW_PORT):9090` to run the command again, and remeber the port is always needed in the URL of HTTP endpoint. \n",
    "\n",
    "```bash\n",
    "docker run --rm -it -v $(PWD):/opt/ai-serving -p 9090:9090 -p 9091:9091 autodeployai/ai-serving\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional information about two python files\n",
    "In the current directory, there are two python files `onnx_ml_pb2.py` and `ai_serving_pb2.py`, which are generated from compiling the [two proto files](https://github.com/autodeployai/ai-serving/tree/master/src/main/protobuf) using [protoc](https://developers.google.com/protocol-buffers/docs/pythontutorial), for example, the command as follows:\n",
    "\n",
    "```bash\n",
    "protoc -I=$SRC_DIR --python_out=. ai-serving.proto onnx-ml.proto\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependency libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import numpy as np\n",
    "import requests\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import onnx_ml_pb2\n",
    "import ai_serving_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the base HTTP URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the port number 9090 to the appropriate port number \n",
    "# if you had changed it during AI-Serving docker instantiation\n",
    "port = 9090\n",
    "base_url = 'http://localhost:' + str(port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the server whether available\n",
    "Use the specific endpoint `http://host:port/up` to test whether the server has been initialized and is ready to accept requests. The `OK` message indicates it's available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server status message:  OK\n"
     ]
    }
   ],
   "source": [
    "test_url = base_url + '/up'\n",
    "response = requests.get(test_url)\n",
    "print('The server status message: ', response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model `mnist/model.onnx` into AI-Serving\n",
    "First, we need to deploy the MNIST ONNX model into AI-Serving, which can serve multiple models, or multiple versions for a named model at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model deployed info:  {'name': 'mnist', 'version': 1}\n"
     ]
    }
   ],
   "source": [
    "# The specified servable name\n",
    "model_name = 'mnist'\n",
    "deployment_url = base_url + '/v1/models/' + model_name\n",
    "\n",
    "# The content type could be one of those three options for ONNX models.\n",
    "# 1. application/octet-stream, \n",
    "# 2. application/vnd.google.protobuf\n",
    "# 3. application/x-protobuf\n",
    "headers = {'Content-Type': 'application/x-protobuf'}\n",
    "\n",
    "model_path = path.join('mnist', 'model.onnx')\n",
    "with open(model_path, 'rb') as file:\n",
    "    deployment_response = requests.put(deployment_url, headers=headers, data=file)\n",
    "\n",
    "# The response is a JSON object contains the sepcified servable name and the model version deployed\n",
    "model_deployed_info = deployment_response.json()\n",
    "print('Model deployed info: ', model_deployed_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get metadata of the deployed model\n",
    "The metadata will contain model input and output fields info, which is needed when constructing an input request and consume an output response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model metadata info:\n",
      "{'createdAt': '2020-04-23T07:00:41',\n",
      " 'id': '81009106-041d-4481-8b8b-92f9097e0cb4',\n",
      " 'latestVersion': 1,\n",
      " 'name': 'mnist',\n",
      " 'updateAt': '2020-04-23T07:00:41',\n",
      " 'versions': [{'createdAt': '2020-04-23T07:00:41',\n",
      "               'hash': 'd7cd24a0a76cd492f31065301d468c3d',\n",
      "               'outputs': [{'name': 'Plus214_Output_0',\n",
      "                            'shape': [1, 10],\n",
      "                            'type': 'tensor(float)'}],\n",
      "               'predictors': [{'name': 'Input3',\n",
      "                               'shape': [1, 1, 28, 28],\n",
      "                               'type': 'tensor(float)'}],\n",
      "               'runtime': 'ONNX Runtime',\n",
      "               'serialization': 'onnx',\n",
      "               'size': 26454,\n",
      "               'type': 'ONNX',\n",
      "               'version': 1}]}\n"
     ]
    }
   ],
   "source": [
    "model_version = model_deployed_info['version']\n",
    "metadata_url = base_url + '/v1/models/' + model_name + '/versions/' + str(model_version)\n",
    "metadata_response = requests.get(metadata_url)\n",
    "\n",
    "print('The model metadata info:')\n",
    "pprint(metadata_response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the input images\n",
    "We will use the sample test data in the compressed file `mnist.tar.gz`, there are 3 test cases that include both input and output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_tensors = []\n",
    "input_arrays = []\n",
    "output_tensors = []\n",
    "output_arrays = []\n",
    "output_digits = []\n",
    "\n",
    "def postprocess(result):\n",
    "    \"\"\"postprocess the predicted results\"\"\"\n",
    "    return int(np.argmax(np.array(result).squeeze(), axis=0))\n",
    "\n",
    "# Read the three test data sets and show them.\n",
    "fig = plt.figure()\n",
    "model_dir = 'mnist'\n",
    "for i in range(3):\n",
    "    input_test_data_set = path.join(model_dir, 'test_data_set_{0}'.format(i), 'input_0.pb')\n",
    "    output_test_data_set = path.join(model_dir, 'test_data_set_{0}'.format(i), 'output_0.pb')\n",
    "    \n",
    "    # Read the input data\n",
    "    input_tensor = onnx_ml_pb2.TensorProto()\n",
    "    with open(input_test_data_set, 'rb') as f:\n",
    "        input_tensor.ParseFromString(f.read())\n",
    "    input_tensors.append(input_tensor)\n",
    "    input_tensor_array = np.frombuffer(input_tensor.raw_data, dtype=np.float32).astype('float32')\n",
    "    input_arrays.append(input_tensor_array)\n",
    "    \n",
    "    # Read the output data\n",
    "    output_tensor = onnx_ml_pb2.TensorProto()\n",
    "    with open(output_test_data_set, 'rb') as f:\n",
    "        output_tensor.ParseFromString(f.read())\n",
    "    output_tensors.append(output_tensor)\n",
    "    output_tensor_array = np.frombuffer(output_tensor.raw_data, dtype=np.float32).astype('float32')\n",
    "    output_arrays.append(output_tensor_array)\n",
    "    output_digit = postprocess(output_tensor_array)\n",
    "    output_digits.append(output_digit)\n",
    "    \n",
    "    # Add a subplot for the current digit.\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(input_tensor_array.reshape([28, 28]), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Digit: {}\".format(output_digit))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTP request formats for the AI-Serving\n",
    "The request for AI-Serving could have two formats: JSON and binary, the HTTP header Content-Type tells the server which format to handle and thus it is required for all requests. The binary payload has better latency, especially for the big tensor value for ONNX models, while the JSON format is easy for human readability.\n",
    "\n",
    "- Content-Type: application/octet-stream, application/vnd.google.protobuf or application/x-protobuf. The request body must be the protobuf message PredictRequest, besides of those common scalar values, it can use the standard TensorProto value directly.\n",
    "\n",
    "\n",
    "- Content-Type: application/json. The request body must be a JSON object formatted as described [here](https://github.com/autodeployai/ai-serving#4-predict-api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the binary requests for the AI-Serving\n",
    "Create both instances of PredictRequest, one is using the `Records` format that has one case, the other is using the `Split` that contains two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_serving_pb2 import RecordSpec, Record, PredictRequest, ListValue, Value\n",
    "\n",
    "# Create an instance of RecordSpec with records that contains only the first tensor.\n",
    "request_message_records = PredictRequest(X=RecordSpec(\n",
    "    records=[Record(fields={'Input3': Value(tensor_value=input_tensors[0])})]\n",
    "))\n",
    "\n",
    "# Create an instance of RecordSpec with columns and data that contains the last two tensors.\n",
    "request_message_split = PredictRequest(X=RecordSpec(\n",
    "    columns = ['Input3'],\n",
    "    data = [\n",
    "        ListValue(values=[Value(tensor_value=input_tensors[1])]),\n",
    "        ListValue(values=[Value(tensor_value=input_tensors[2])])\n",
    "    ]\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the HTTP requests with binary data to the AI-Serving\n",
    "Make predictions using the AI-Serving, the content type of requests with binary data must be one of those three candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'Content-Type': 'application/x-protobuf'}\n",
    "\n",
    "# When version is omitted, the latest version is used.\n",
    "prediction_url = base_url + '/v1/models/' + model_name\n",
    "\n",
    "# Make prediction for the `records` request message.\n",
    "prediction_response_records = requests.post(prediction_url, \n",
    "                                           headers=headers, \n",
    "                                           data=request_message_records.SerializeToString())\n",
    "\n",
    "# Make prediciton for the `split` request message.\n",
    "prediction_response_split = requests.post(prediction_url, \n",
    "                                           headers=headers, \n",
    "                                           data=request_message_split.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume the HTTP response with binary data from the AI-serving\n",
    "Having received the results from the server, we are going to parse the \"serialized\" message that we just received for us to make sense of the results. And compare the actual results to the desired ones. \n",
    "\n",
    "**NOTE: The data format of the output response is always the same as the input request.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual output shape of test data set 0:  [1, 10]\n",
      "Actual output values of test data set 0:  [  975.67035   -618.7242    6574.5654     668.0283    -917.27106\n",
      " -1671.6361   -1952.7599     -61.549576  -777.17645  -1439.5316  ]\n",
      "Actual final recognized digit of test data set 0:  2\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Acutal output columns:  ['Plus214_Output_0']\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Actual output shape of test data set 1:  [1, 10]\n",
      "Actual output values of test data set 1:  [ 5041.8896   -3568.8784    -187.82423  -1685.797    -1183.3229\n",
      "  -614.4292     892.66406   -373.659     -290.26212   -111.176254]\n",
      "Actual final recognized digit of test data set 1:  0\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Actual output shape of test data set 2:  [1, 10]\n",
      "Actual output values of test data set 2:  [-2334.0884   -1113.6252    1076.5806    -860.2392    1588.5349\n",
      " -1534.3469   -2686.0774     -56.480537    74.57544   3715.38    ]\n",
      "Actual final recognized digit of test data set 2:  9\n"
     ]
    }
   ],
   "source": [
    "def print_output_and_compare_result(index, output_tensor):\n",
    "    # Print the actual result for the tensor\n",
    "    actual_output_tensor_array = np.asarray(output_tensor.float_data, dtype=np.dtype('float32'))\n",
    "    print('Actual output shape of test data set {}: '.format(index), output_tensor.dims)\n",
    "    print('Actual output values of test data set {}: '.format(index), actual_output_tensor_array)\n",
    "    print('Actual final recognized digit of test data set {}: '.format(index), postprocess(actual_output_tensor_array))\n",
    "    \n",
    "    # Both results are expected be equal to each other.\n",
    "    np.testing.assert_almost_equal(actual_output_tensor_array, output_arrays[index], 1)\n",
    "    np.testing.assert_equal(postprocess(actual_output_tensor_array), output_digits[index])\n",
    "\n",
    "\n",
    "# Parse the response message from the `recrods` request.\n",
    "response_message = ai_serving_pb2.PredictResponse()\n",
    "response_message.ParseFromString(prediction_response_records.content)\n",
    "\n",
    "# Print and compare the result for the test data set 0\n",
    "print_output_and_compare_result(0, response_message.result.records[0].fields['Plus214_Output_0'].tensor_value)\n",
    "print('\\n----------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Parse the response message from the `split` requesgt.\n",
    "response_message = ai_serving_pb2.PredictResponse()\n",
    "response_message.ParseFromString(prediction_response_split.content)\n",
    "\n",
    "print('Acutal output columns: ', response_message.result.columns)\n",
    "print('\\n----------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Print and compare the result for the test data set 1\n",
    "print_output_and_compare_result(1, response_message.result.data[0].values[0].tensor_value)\n",
    "\n",
    "print('\\n----------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Print and compare the result for the test data set 2\n",
    "print_output_and_compare_result(2, response_message.result.data[1].values[0].tensor_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct JSON requests for the AI-Serving\n",
    "Create both JSON objects, one is using the `Records` format that has one case, the other is using `Split` that contains two cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a JSON object with records that contains only the first tensor.\n",
    "request_json_recoreds = {\n",
    "    'X': [{\n",
    "        'Input3': input_arrays[0].tolist()\n",
    "    }]\n",
    "}\n",
    "\n",
    "# Create a JSON object with columns and data that contains the last two tensors.\n",
    "request_json_split = {\n",
    "    'X': {\n",
    "        'columns': ['Input3'],\n",
    "        'data': [[input_arrays[1].tolist()], [input_arrays[2].tolist()]]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the HTTP requests with JSON data to the AI-Serving\n",
    "Make predictions using the AI-Serving, the content type of requests with JSON data must be `application/json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When version is omitted, the latest version is used.\n",
    "prediction_url = base_url + '/v1/models/' + model_name\n",
    "\n",
    "# The Content-Type: application/json is specified implicitly when using json instead of data\n",
    "prediction_json_response_records = requests.post(prediction_url, json=request_json_recoreds)\n",
    "prediction_json_response_split = requests.post(prediction_url, json=request_json_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume the HTTP response with JSON data from the AI-serving\n",
    "Having received the results from the server, we are going to parse the JSON text that we just received for us to make sense of the results. And compare the actual results to the desired ones.\n",
    "\n",
    "**NOTE: The data format of the output response is always the same as the input request.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The response json from the `records` request:\n",
      "{'result': [{'Plus214_Output_0': [[975.6703491210938,\n",
      "                                   -618.7241821289062,\n",
      "                                   6574.5654296875,\n",
      "                                   668.0283203125,\n",
      "                                   -917.2710571289062,\n",
      "                                   -1671.6361083984375,\n",
      "                                   -1952.7598876953125,\n",
      "                                   -61.54957580566406,\n",
      "                                   -777.1764526367188,\n",
      "                                   -1439.5316162109375]]}]}\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Actual output shape of test data set 0:  (10,)\n",
      "Actual output values of test data set 0:  [  975.67035   -618.7242    6574.5654     668.0283    -917.27106\n",
      " -1671.6361   -1952.7599     -61.549576  -777.17645  -1439.5316  ]\n",
      "Actual final recognized digit of test data set 0:  2\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "The response json from the `split` request:\n",
      "{'result': {'columns': ['Plus214_Output_0'],\n",
      "            'data': [[[[5041.8896484375,\n",
      "                        -3568.87841796875,\n",
      "                        -187.82423400878906,\n",
      "                        -1685.7969970703125,\n",
      "                        -1183.3228759765625,\n",
      "                        -614.42919921875,\n",
      "                        892.6640625,\n",
      "                        -373.65899658203125,\n",
      "                        -290.2621154785156,\n",
      "                        -111.17625427246094]]],\n",
      "                     [[[-2334.08837890625,\n",
      "                        -1113.625244140625,\n",
      "                        1076.58056640625,\n",
      "                        -860.2391967773438,\n",
      "                        1588.534912109375,\n",
      "                        -1534.346923828125,\n",
      "                        -2686.077392578125,\n",
      "                        -56.48053741455078,\n",
      "                        74.575439453125,\n",
      "                        3715.3798828125]]]]}}\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Actual output shape of test data set 1:  (10,)\n",
      "Actual output values of test data set 1:  [ 5041.8896   -3568.8784    -187.82423  -1685.797    -1183.3229\n",
      "  -614.4292     892.66406   -373.659     -290.26212   -111.176254]\n",
      "Actual final recognized digit of test data set 1:  0\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "\n",
      "Actual output shape of test data set 2:  (10,)\n",
      "Actual output values of test data set 2:  [-2334.0884   -1113.6252    1076.5806    -860.2392    1588.5349\n",
      " -1534.3469   -2686.0774     -56.480537    74.57544   3715.38    ]\n",
      "Actual final recognized digit of test data set 2:  9\n"
     ]
    }
   ],
   "source": [
    "def print_json_output_and_compare_result(index, output_list):\n",
    "    # Print the actual result for the tensor\n",
    "    actual_output_tensor_array = np.asarray(output_list, dtype=np.dtype('float32')).reshape(output_arrays[index].shape)\n",
    "    print('Actual output shape of test data set {}: '.format(index), actual_output_tensor_array.shape)\n",
    "    print('Actual output values of test data set {}: '.format(index), actual_output_tensor_array)\n",
    "    print('Actual final recognized digit of test data set {}: '.format(index), postprocess(actual_output_tensor_array))\n",
    "    \n",
    "    # Both results are expected be equal to each other.\n",
    "    np.testing.assert_almost_equal(actual_output_tensor_array, output_arrays[index], 1)\n",
    "    np.testing.assert_equal(postprocess(actual_output_tensor_array), output_digits[index])\n",
    "\n",
    "\n",
    "# Parse the response json from the `recrods` request.\n",
    "response_json = prediction_json_response_records.json()\n",
    "print('The response json from the `records` request:')\n",
    "pprint(response_json)\n",
    "print('\\n----------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Print and compare the result for the test data set 0\n",
    "print_json_output_and_compare_result(0, response_json['result'][0]['Plus214_Output_0'])\n",
    "print('\\n----------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Parse the response json from the `split` requesgt.\n",
    "response_json = prediction_json_response_split.json()\n",
    "print('The response json from the `split` request:')\n",
    "pprint(response_json)\n",
    "print('\\n----------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Print and compare the result for the test data set 1\n",
    "print_json_output_and_compare_result(1, response_json['result']['data'][0])\n",
    "\n",
    "print('\\n----------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Print and compare the result for the test data set 2\n",
    "print_json_output_and_compare_result(2, response_json['result']['data'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
